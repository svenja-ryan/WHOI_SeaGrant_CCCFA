{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf84b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "## example code from Hendrik\n",
    "\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import dask\n",
    "\n",
    "#stats.personr only works on dataarrays, so select your variable at one point\n",
    "data = xr.open_dataset('subset.nc').sst \n",
    "\n",
    "#maybe mfdataset helps for huge datasets and then parallization; 39 is the size of time, you want all time points to be in one chunk\n",
    "# data = xr.open_mfdataset('subset.nc',chunks={'time':39,'lat':100,'lon':100}).sst \n",
    "\n",
    "#stats.pearsonr doesnt allow nan inputs, so put nan to 0; it then returns nan again for correlation along constant arrays\n",
    "data = data.fillna(0)\n",
    "\n",
    "def correlation(data1,data2):\n",
    "    # data1 is the spatial field you want to correlate to\n",
    "    # data2 is your single time series\n",
    "    # calculates the correlation coefficient and p_value\n",
    "    # returns the result as a numpy array, because the initial output of the function is of a weird PearsonRResult class, which doesnt work in apply_ufunc\n",
    "    result = stats.pearsonr(data1,data2)\n",
    "    return np.stack((result[0],result[1]), axis=-1)\n",
    "\n",
    "# apply_ufunc takes the function you want to apply and then the necessary input arguments to that function\n",
    "# so data is your spatial field and then your single time series (I just selected one pointfrom my field)\n",
    "# the input_core_dimensions basically mean along which dimension your function is applied on\n",
    "# the output dimension is necesarry because the correlation output is of size 2\n",
    "# dask='parallelized' makes it faster, but needs some additional arguments for your output\n",
    "\n",
    "result = xr.apply_ufunc(correlation,data,data.isel(lat=50,lon=50),\n",
    "                        input_core_dims=[['time'],['time']],\n",
    "                        output_core_dims=[['statistic']],vectorize=True,\n",
    "                        dask='parallelized',output_dtypes=[np.dtype(float)],\n",
    "                        dask_gufunc_kwargs={'output_sizes':{'statistic':2}})\n",
    "\n",
    "# make xarray dataset of the output, because the output has r and p along one extra dimension, so assign them to single variables\n",
    "statistics = xr.Dataset(coords={'lat':result.lat,'lon':result.lon}, data_vars = {\n",
    "    'corrcoef':result[:,:,0],\n",
    "    'p_value':result[:,:,1]\n",
    "})\n",
    "\n",
    "# necessary if you use mfdatasets, so you finally compute the correlation for each chunk\n",
    "# statistics = statistics.compute()\n",
    "\n",
    "statistics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
